{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCFoST6gr1pX",
        "outputId": "1966978e-50f5-49dc-f1fa-6d41cb490ee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 31.0 MB 1.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install imagecodecs -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "85NfdDqEsKhD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tifffile as tfl\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from loss import bce_dice_loss, dice_coef\n",
        "from metrics import recall_m,precision_m,f1_m\n",
        "from tensorflow import keras\n",
        "import gdal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VO9hVR3JsTCi"
      },
      "outputs": [],
      "source": [
        "model=keras.models.load_model('/content/5_Train_S1_Weak_Label_S1OtsuLabel weak.h5',\n",
        "                                 custom_objects={ 'bce_dice_loss': bce_dice_loss, \n",
        "                                                 'dice_coef':dice_coef,\n",
        "                                                 'f1_m':f1_m,\n",
        "                                                 'precision_m':precision_m,\n",
        "                                                 'recall_m':recall_m} )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPWb7MOfsc14",
        "outputId": "0a7d670b-d0ce-471d-f3d7-459457dc7572"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7078, 4037, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "sentinel1_img = '/content/drive/MyDrive/GIC_internship_inference/Inference1_sentinel1_data_final.tif'\n",
        "\n",
        "sample = tfl.imread(sentinel1_img)\n",
        "sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HytEqhCvsc4Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2 as cv2\n",
        "import PIL\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import gdal\n",
        "import tifffile as tif\n",
        "\n",
        "def pad(save_dir,src_img, model_input_w, model_input_h):\n",
        "    \"\"\"\n",
        "    Add extra black area to image to make it ready for cropping\n",
        "    \n",
        "    arguments:\n",
        "        save_dir (Directory) : Directory to store your padded image\n",
        "        src_img (PIL (or) np array): image to be padded\n",
        "        model_input_w (int): input image width for model   \n",
        "        model_input_h (int): input image height for model\n",
        "    \n",
        "    returns:\n",
        "        PIL image: padded image\n",
        "    \"\"\"\n",
        "    \n",
        "    img_type = type(src_img)\n",
        "\n",
        "    # change to numpy array\n",
        "    if img_type  == np.ndarray : \n",
        "        img = src_img.copy()\n",
        "    else: \n",
        "        img = np.array(src_img)\n",
        "    \n",
        "    img_width = img.shape[1]\n",
        "    img_height = img.shape[0]\n",
        "    \n",
        "    pad_width = int((np.ceil(img_width / model_input_w) * model_input_w) - img_width)\n",
        "    pad_height = int((np.ceil(img_height / model_input_h) * model_input_h) - img_height)\n",
        "    \n",
        "    print('image width = ', img_width, ', image height = ', img_height)\n",
        "    print('pad width = ', pad_width, ', pad height = ', pad_height)\n",
        "    \n",
        "    result_image = cv2.copyMakeBorder( img, 0, pad_height, 0, pad_width, cv2.BORDER_CONSTANT)\n",
        "    os.makedirs(save_dir,exist_ok= True)\n",
        "    print('Padded Image shape',result_image.shape)\n",
        "    tif.imwrite(str(save_dir)+'padded_image.tif',result_image)\n",
        "    \n",
        "    return result_image\n",
        "\n",
        "def crop( gdal_dataset,model_input_w ,model_input_h ,save_dir):\n",
        "    \"\"\"\n",
        "      gdal_dataset : read the tifffile using gdal.Open and pass it to gdal_dataset\n",
        "      model_input_w : width of model input\n",
        "      model_input_h : height of model input\n",
        "      save_dir : Directory to store data\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    ds = gdal_dataset\n",
        "    # ds = gdal.Open('/content/padded_img.tif')\n",
        "    print(ds.ReadAsArray().shape)\n",
        "    img_height = ds.ReadAsArray().shape[1] #2\n",
        "    img_width  = ds.ReadAsArray().shape[2] #1\n",
        "\n",
        "    os.makedirs(save_dir,exist_ok = True )\n",
        "\n",
        "    box_list =[]\n",
        "    arr = []\n",
        "    for i in range(img_height//model_input_h):\n",
        "        # hori = []\n",
        "        for j in range(img_width//model_input_w):\n",
        "            box = [j*model_input_w, i*model_input_h, 512,512]\n",
        "            print(\"coordinates\",box[:2])\n",
        "            box_list.append(box[:2])\n",
        "            # gdal.Translate('/content/cropped_images/cropped_images_'+str(i)+'_'+str(j)+'.tif',ds,srcWin=box)\n",
        "            gdal.Translate(str(save_dir)+'cropped_images_'+str(i)+'_'+str(j)+'.tif',ds,srcWin=box)\n",
        "            arr.append(str(save_dir)+'cropped_images_'+str(i)+'_'+str(j)+'.tif')\n",
        "\n",
        "        \n",
        "    \n",
        "  \n",
        "    return arr,box_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def reconstruct(preds,img_height,img_width,model_input_h,model_input_w,box_list,numpy=False):\n",
        "  pred_list = list(preds)\n",
        "\n",
        "  tiles_list = [Image.fromarray(i, 'L') for i in pred_list]\n",
        "\n",
        "  first_image = tiles_list[0]\n",
        "\n",
        "  num_row = int(np.ceil(img_height / model_input_h))\n",
        "  num_col = int(np.ceil(img_width / model_input_w))\n",
        "\n",
        "  print(num_row,num_col)\n",
        "\n",
        "\n",
        "\n",
        "  # create a blank sheet\n",
        "  contact_sheet=PIL.Image.new(first_image.mode, (first_image.width * num_col,first_image.height * num_row))\n",
        "  x, y = 0, 0\n",
        "  for img,j in zip(tiles_list,box_list):\n",
        "    # print(img,j)\n",
        "    # paste a single tile in sheet\n",
        "    contact_sheet.paste(img, j )\n",
        "    # calculate next position\n",
        "    if x+first_image.width == contact_sheet.width:\n",
        "        x=0\n",
        "        y=y+first_image.height\n",
        "    else:\n",
        "        x=x+first_image.width\n",
        "  # remove extra padded area\n",
        "  crop_box = (0, 0, 4037,7078)\n",
        "  print(crop_box)\n",
        "  new_img = contact_sheet.crop(crop_box)\n",
        "  # new_img = contact_sheet\n",
        "\n",
        "  if numpy == True:\n",
        "    new_img = np.array(new_img)\n",
        "\n",
        "\n",
        "\n",
        "  return new_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQnx2EBfsc6e",
        "outputId": "855eb002-0eea-45b7-adac-dae7022b2986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image width =  4037 , image height =  7078\n",
            "pad width =  59 , pad height =  90\n",
            "Padded Image shape (7168, 4096, 3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "padded_img = pad(\"/content/padded_image_v2/\",tif.imread(sentinel1_img),512,512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aaNkersmsc_P"
      },
      "outputs": [],
      "source": [
        "original_img = tif.imread(sentinel1_img)\n",
        "pad_img = tif.imread('/content/padded_image_v2/padded_image.tif')\n",
        "\n",
        "img_width , img_height = original_img.shape[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjJRYJhksdCg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig,(ax1,ax2)= plt.subplots(1,2,figsize=(15,10))\n",
        "ax1.imshow(original_img[:,:,0])\n",
        "ax1.set_title(original_img.shape)\n",
        "ax2.imshow(pad_img[:,:,0])\n",
        "ax2.set_title(pad_img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCE5D5U_deyX"
      },
      "outputs": [],
      "source": [
        "ds = gdal.Open('/content/padded_image_v2/padded_image.tif')\n",
        "# ds_arr = ds.ReadAsArray()\n",
        "# print(ds_arr.shape)\n",
        "\n",
        "arr,box_list = crop(ds,512,512,'/content/test_cropped_version/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRewDHX8e7Gm"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "cropped_tiles = []\n",
        "# cr_images =glob.glob('/content/cropped_images/*.tif')\n",
        "\n",
        "for i in arr:\n",
        "  # print(i)\n",
        "  cr_images_gdal= np.moveaxis(gdal.Open(i).ReadAsArray(),0,-1)\n",
        "  cropped_tiles.append(cr_images_gdal)\n",
        "\n",
        "cropped_tiles_arr = np.array(cropped_tiles)\n",
        "print(cropped_tiles_arr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XvXnNy5f370"
      },
      "outputs": [],
      "source": [
        "cropped_tiles_arr =cropped_tiles_arr[:,:,:,:2]\n",
        "model_predictions = model.predict(cropped_tiles_arr,verbose=1)\n",
        "\n",
        "preds = np.squeeze(model_predictions)\n",
        "\n",
        "threshold = 0.01\n",
        "preds = preds > threshold\n",
        "#preds =np.argmax(preds[0],axis=-1)\n",
        "print(preds.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_img = reconstruct(preds,img_width,img_height,512,512,box_list,True)"
      ],
      "metadata": {
        "id": "4Bdqke0gQ4Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,(ax1,ax2) =plt.subplots(1,2,figsize=(15,10))\n",
        "ax1.imshow(new_img)\n",
        "ax1.set_title(f'Shape of data {new_img.shape}')\n",
        "ax2.imshow(original_img[:,:,0])\n",
        "ax2.set_title(f'Original Image shape {original_img.shape}')"
      ],
      "metadata": {
        "id": "k3weXQ3URKCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B0qI2MCHUOyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GIC_inferencing_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}